{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Administrative Outcomes Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Setup Development Environment \n",
    "\n",
    "<!-- - Install Poetry to simplify dependency management. \n",
    "    - `pip install poetry` \n",
    "- Setup Poetery Project \n",
    "    - `poetry init` \n",
    "- Create a virtual envrionment \n",
    "    - `python -m venv .venv` \n",
    "- Add dependencies \n",
    "    - `poetry add pyspark ipykernel pandas matplotlib ploty`\n",
    "\n",
    "**Apache Spark**\n",
    "\n",
    "**Apache Iceberg** -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FhirDataApplication\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"dataset/iceberg\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Integration\n",
    "\n",
    "<!-- Data integration with Fast Healthcare Interoperability Resources (FHIR) resources involves unifying healthcare data from multiple systems to enable seamless data exchange and interoperability. This approach enhances data consistency, accessibility, and streamlines access to critical healthcare information across applications and organizations.\n",
    "\n",
    "**Data Source: MIMIC-IV on FHIR**\n",
    "\n",
    "The project uses MIMIC-IV on FHIR as its primary data source. This dataset provides a rich, de-identified healthcare database mapped to the FHIR (Fast Healthcare Interoperability Resources) standard to support interoperability and advanced analytics in healthcare research.\n",
    "\n",
    "MIMIC-IV on FHIR is a project by PhysioNet designed to translate the structure and content of MIMIC-IV into the FHIR standard. MIMIC-IV is a relational database containing real hospital stay data for patients admitted to a tertiary academic medical center in Boston, MA, USA. It includes comprehensive clinical and administrative information recorded between 2008 and 2019.\n",
    "\n",
    "By leveraging MIMIC-IV on FHIR, this project aims to enhance data interoperability and enable the development of predictive models and analytical insights aligned with modern healthcare standards and regulatory compliance.\n",
    "\n",
    "**Fast Healthcare Interoperability Resources (FHIR)**\n",
    "\n",
    "FHIR is a specification for exchanging health care data across different systems and platforms. The specification builds on and adapts modern, widely used RESTful practices to enable the provision of integrated healthcare across a wide range of teams and organizations. FHIR is based on \"Resources\" which are the common building blocks for all exchanges.\n",
    "\n",
    "Key FHIR Resources for Integration:\n",
    "\n",
    "- Patient: Stores demographic information such as name, age, and contact details.\n",
    "- Encounter: Captures details of patient visits and interactions with healthcare providers.\n",
    "- Condition: Represents diagnoses and health conditions affecting the patient.\n",
    "- Procedure: Records medical procedures and interventions performed.\n",
    "- Observation: Contains lab results, vital signs, and other clinical observations.\n",
    "\n",
    "**Medallion Architecture**\n",
    "\n",
    "The project follows a Medallion Architecture framework, which organizes data into multiple layers to ensure structured data refinement, improved data quality, and optimized analytics. This approach enhances data governance and enables efficient processing for downstream use cases.\n",
    "\n",
    "The architecture comprises three key layers:\n",
    "1. Bronze Layer (Raw Data): The Bronze layer stores raw, ingested data from various source systems without transformations. It retains all original fields and formats, providing a comprehensive source of truth for historical and traceability purposes.\n",
    "\n",
    "2. Silver Layer (Filtered, Cleaned, Augmented): The Silver layer refines and transforms the raw data, selecting only the necessary fields from relevant FHIR resources (e.g., Patient, Encounter, Condition, Procedure). This layer provides clean, structured, and domain-specific datasets for targeted analysis and processing.\n",
    "\n",
    "3. Gold Layer (Business-Level Aggregrates): The Gold layer aggregates data into a unified, optimized format for advanced analytics and reporting. In this project, it focuses on a Consolidated Encounter Table, combining encounter data with relevant patient demographics, conditions, and other clinical information to support predictive modeling and operational insights.\n",
    "\n",
    "This layered architecture promotes scalability, data quality, and efficient data retrieval, aligning with best practices for healthcare data management and analytics.\n",
    "\n",
    "> **References**\n",
    "> - [MIMIC Implementatoin Guide | KinD Lab](https://mimic.mit.edu/fhir/)\n",
    "> - [FHIR Documentation | HL7FHIR](https://www.hl7.org/fhir/)\n",
    "> - [Medallion Architecture | Databricks](https://www.databricks.com/glossary/medallion-architecture) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze Layer\n",
    "\n",
    "<!-- The Bronze Layer serves as the foundation of the data architecture, capturing raw, untransformed data from various source systems. It retains all original fields and formats, providing a comprehensive source of truth for historical and traceability purposes. This layer plays a crucial role in maintaining data integrity, enabling auditability, and supporting complex analytical workflows in later stages.\n",
    "\n",
    "In the project, `bronze.resource` serves as a storage for raw data that has been ingested from various source files. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "  CREATE TABLE IF NOT EXISTS local.bronze.resource ( \n",
    "    sourceFile STRING, \n",
    "    value STRING \n",
    "  ) USING iceberg; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_FILES = [\"MimicPatient.ndjson.gz\", \"MimicCondition.ndjson.gz\", \"MimicConditionED.ndjson.gz\", \"MimicEncounter.ndjson.gz\", \"MimicEncounterED.ndjson.gz\", \"MimicEncounterICU.ndjson.gz\"] \n",
    "for resource_file in RESOURCE_FILES: \n",
    "    resource_df = spark.read.text(f\"dataset/{resource_file}\") \n",
    "    resource_df = resource_df.withColumn(\"sourceFile\", F.lit(resource_file)) \n",
    "    resource_df.write.format(\"iceberg\").mode(\"append\").save(\"local.bronze.resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver Layer\n",
    "\n",
    "<!-- The Silver Table represents the refined data layer in the Medallion Architecture, where raw data from the Bronze Layer is transformed and cleansed. It focuses on structuring the data and selecting only the necessary fields from relevant sources, ensuring that it is ready for more detailed analysis and reporting.\n",
    "\n",
    "The Silver Tables in use include Patient, Encounter, and Condition. The Patient table stores essential demographic information, while the Encounter table tracks patient visits and interactions with healthcare providers. The Condition table holds information about patient diagnoses and health conditions.\n",
    "\n",
    "The resources are stored while adhering to Safe Harbor provisions to ensure patient privacy and compliance with data protection regulations.\n",
    "\n",
    "**Safe Harbor Provisions**\n",
    "\n",
    "Safe Harbor provisions are a set of guidelines that allow organizations to de-identify personal data in a way that ensures compliance with privacy regulations, particularly in the context of healthcare and data protection laws like HIPAA. Under these provisions, data can be stripped of specific identifiers, such as names, addresses, and Social Security numbers, making it no longer considered protected health information (PHI). Safe Harbor provisions offer a balance between privacy protection and the need for data availability, enabling the use of anonymized data while minimizing the risk of re-identification.\n",
    "\n",
    "\n",
    "> **References**\n",
    "> - [Guidance Regarding Methods for De-identification of PHI](https://www.hhs.gov/hipaa/for-professionals/special-topics/de-identification/index.html) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bronze Table\n",
    "raw_df = spark.read.format(\"iceberg\").load(\"local.bronze.resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Mart\n",
    "\n",
    "<!-- The Patient Mart stores essential demographic information for each patient, providing a foundational set of details necessary for understanding patient profiles and is used in various healthcare processes, from clinical interactions to research and analysis.\n",
    "\n",
    "| Column Name   | Description                                   |\n",
    "|---------------|-----------------------------------------------|\n",
    "| patientID     | A unique identifier assigned to each patient. |\n",
    "| gender        | The patient's gender (e.g., male or female).  |\n",
    "| birthDate     | The patient's date of birth.                  |\n",
    "| maritalStatus | The marital status of the patient.            | -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.patient (\n",
    "    patientId STRING,\n",
    "    gender STRING,\n",
    "    birthDate DATE,\n",
    "    maritalStatus STRING,\n",
    "    sourceFile STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicPatient.ndjson.gz\"))\n",
    "with open(\"schema/Patient.json\") as f:\n",
    "    schema_read = json.loads(f.read())\n",
    "schema = T.StructType.fromJson(schema_read)\n",
    "patient_df = patient_df.withColumn(\"parsed_json\", F.from_json(patient_df[\"value\"], schema))\n",
    "patient_df = patient_df.select(\"parsed_json.*\", \"sourceFile\")\n",
    "patient_df.createOrReplaceTempView(\"patient_df\")\n",
    "\n",
    "fm_patient = spark.sql(\"\"\"\n",
    "select\n",
    "    id AS patientId,\n",
    "    gender AS gender,\n",
    "    to_date(birthDate) birthDate,\n",
    "    CASE maritalStatus.coding[0].code\n",
    "        WHEN \"M\" THEN \"Married\"\n",
    "        WHEN \"D\" THEN \"Divorced\"\n",
    "        WHEN \"W\" THEN \"Widowed\"\n",
    "        WHEN \"S\" THEN \"Never Married\"\n",
    "        ELSE \"Unknown\"\n",
    "    END maritalStatus,\n",
    "    sourceFile\n",
    "from patient_df\n",
    "\"\"\")\n",
    "\n",
    "fm_patient.show(5, truncate=False)\n",
    "fm_patient.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encounter Mart\n",
    "\n",
    "<!-- The Encounter resource represents an interaction between a patient and healthcare provider(s) for the purpose of delivering healthcare services or assessing the patient’s health status.\n",
    "\n",
    "It captures the full span of a hospital stay, from admission to discharge, and includes important details such as the start and end time of the admission, the context surrounding the admission, and patient movements within the healthcare facility.\n",
    "\n",
    "| Column            | Description                                                                                                                          |\n",
    "|-------------------|--------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| encounterId       | A unique identifier for the encounter.                                                                                               |\n",
    "| patientId         | A unique identifier for the patient involved in the encounter.                                                                       |\n",
    "| ref_encounterId   | A reference to a related encounter, which may relate to both future and past encounters.                                             |\n",
    "| periodStart       | The start timestamp marking the beginning of the encounter period.                                                                   |\n",
    "| periodEnd         | The end timestamp marking the conclusion of the encounter period.                                                                    |\n",
    "| duration          | The total duration of the encounter, typically in hours or days.                                                                     |\n",
    "| status            | The current status of the encounter (e.g., planned, in-progress, finished).                                                          |\n",
    "| encounterClass    | The classification of the encounter, such as inpatient or outpatient, helping to categorize the type of healthcare service provided. |\n",
    "| codedType         | A code representing the specific type of encounter, aiding in standardized classification.                                           |\n",
    "| displayType       | A human-readable display name for the type of encounter.                                                                             |\n",
    "| systemType        | The system from which the encounter type code is derived.                                                                            |\n",
    "| priority          | The urgency level of the encounter, which may include options like routine, urgent, or emergency.                                    |\n",
    "| nextEncounterId   | A reference to next encounter                                                                                                        |\n",
    "| readmissionStatus | Future readmission indicator                                                                                                         | -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.encounter (\n",
    "    encounterId STRING,\n",
    "    patientId STRING,\n",
    "    ref_encounterId STRING,\n",
    "    periodStart TIMESTAMP,\n",
    "    periodEnd TIMESTAMP,\n",
    "    duration INT,\n",
    "    status STRING,\n",
    "    encounterClass STRING,\n",
    "    displayType STRING,\n",
    "    admitSource STRING,\n",
    "    dischargeDisposition STRING,\n",
    "    priority STRING,\n",
    "    nextEncounterId STRING,\n",
    "    readmissionStatus STRING,\n",
    "    sourceFile STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicEncounter.ndjson.gz\", \"MimicEncounterED.ndjson.gz\")) \n",
    "with open(\"schema/Encounter.json\") as f: \n",
    "    schema_read = json.loads(f.read()) \n",
    "schema = T.StructType.fromJson(schema_read) \n",
    "encounter_df = encounter_df.withColumn(\"parsed_json\", F.from_json(encounter_df[\"value\"], schema)) \n",
    "encounter_df = encounter_df.select(\"parsed_json.*\", \"sourceFile\") \n",
    "encounter_df.createOrReplaceTempView(\"encounter_df\") \n",
    "\n",
    "fm_encounter = spark.sql(\"\"\" \n",
    "SELECT \n",
    "    id AS encounterId, \n",
    "    replace(subject.reference, \"Patient/\", \"\") AS patientId, \n",
    "    replace(partOf.reference, \"Encounter/\", \"\") AS ref_encounterId, \n",
    "    CAST(period.start AS timestamp) periodStart, \n",
    "    CAST(period.end AS timestamp) periodEnd, \n",
    "    date_diff(day, periodStart, periodEnd) duration, \n",
    "    status AS status, \n",
    "    CASE class.code \n",
    "        WHEN \"AMB\" THEN \"Ambulatory\" \n",
    "        WHEN \"OBSENC\" THEN \"Observation Encounter\" \n",
    "        WHEN \"ACUTE\" THEN \"Inpatient Acute\" \n",
    "        WHEN \"EMER\" THEN \"Emergency\" \n",
    "        WHEN \"SS\" THEN \"Short Stay\" \n",
    "    END AS encounterClass, \n",
    "    type[0].coding[0].display AS displayType, \n",
    "    hospitalization.admitSource.coding[0].code admitSource, \n",
    "    hospitalization.dischargeDisposition.coding[0].code dischargeDisposition, \n",
    "    nvl(priority.coding[0].display, 'emergency') AS priority, \n",
    "    -- Next EncounterID & Readmission Status \n",
    "    LEAD(id) OVER (PARTITION BY subject.reference ORDER BY period.start) AS nextEncounterId, \n",
    "    CASE \n",
    "        WHEN DATEDIFF(day, period.end, LEAD(period.start) OVER (PARTITION BY subject.reference ORDER BY period.start)) <= 30 THEN 'Readmission' \n",
    "        ELSE 'No Readmission' \n",
    "    END AS readmissionStatus, \n",
    "    sourceFile \n",
    "FROM encounter_df \n",
    "\"\"\") \n",
    "\n",
    "fm_encounter.show(5, truncate=False) \n",
    "fm_encounter.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.encounter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition Mart\n",
    "\n",
    "<!-- The Condition resource in FHIR is used to document a patient’s health state, including diagnoses, clinical problems, or other health concerns.\n",
    "\n",
    "It captures conditions that are significant enough to warrant clinical focus, including diseases, health problems, or the state following a medical procedure.\n",
    "\n",
    "This resource plays a critical role in capturing a patient’s health history and providing a detailed record of conditions for clinical decision-making, research, and care management.\n",
    "\n",
    "| Column           | Description                                                                                 |\n",
    "|------------------|---------------------------------------------------------------------------------------------|\n",
    "| conditionId      | A unique identifier for the condition.                                                      |\n",
    "| patientId        | A unique identifier for the patient associated with the condition.                          |\n",
    "| encounterId      | The unique identifier for the encounter where the condition was diagnosed or recorded.      |\n",
    "| categoryCode     | A code representing the category of the condition (e.g., diagnosis, problem).               |\n",
    "| conditionCode    | The code that represents the specific condition, typically from a standardized code system. |\n",
    "| conditionDisplay | A human-readable display name for the condition.                                            |\n",
    "| conditionSystem  | The system from which the condition code is derived (e.g., ICD-10, SNOMED CT).              | -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition ( \n",
    "    conditionId STRING, \n",
    "    patientId STRING, \n",
    "    encounterId STRING, \n",
    "    categoryCode STRING, \n",
    "    conditionCode STRING, \n",
    "    conditionDisplay STRING, \n",
    "    conditionSystem STRING, \n",
    "    sourceFile STRING \n",
    ") USING iceberg; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicCondition.ndjson.gz\", \"MimicConditionED.ndjson.gz\")) \n",
    "with open(\"schema/Condition.json\") as f: \n",
    "    schema_read = json.loads(f.read()) \n",
    "schema = T.StructType.fromJson(schema_read) \n",
    "condition_df = condition_df.withColumn(\"parsed_json\", F.from_json(condition_df[\"value\"], schema)) \n",
    "condition_df = condition_df.select(\"parsed_json.*\", \"sourceFile\") \n",
    "condition_df.createOrReplaceTempView(\"condition_df\") \n",
    "\n",
    "fm_condition = spark.sql(\"\"\" \n",
    "SELECT \n",
    "    id AS conditionId, \n",
    "    replace(subject.reference, \"Patient/\", \"\") AS patientId, \n",
    "    replace(encounter.reference, \"Encounter/\", \"\") AS encounterId, \n",
    "    category[0].coding[0].code categoryCode, \n",
    "    code.coding[0].code AS conditionCode, \n",
    "    code.coding[0].display AS conditionDisplay, \n",
    "    code.coding[0].system AS conditionSystem, \n",
    "    sourceFile \n",
    "FROM condition_df \n",
    "\"\"\") \n",
    "\n",
    "fm_condition.show(5, truncate=False) \n",
    "fm_condition.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"select date_format(birthDate, 'yyyy') birthYear, count(*) count from local.silver.patient group by 1 order by 1\").toPandas(),\n",
    "    x='birthYear',\n",
    "    y='count',\n",
    "    title='Patient BirthYear Distribution [De-Identified]'\n",
    ").update_layout(\n",
    "    xaxis_title='Birth Year',\n",
    "    yaxis_title='Number of Patients',\n",
    "    template='plotly_white'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select gender, count(*) count from local.silver.patient group by 1 order by 1\").toPandas(),\n",
    "    values='count', names='gender', title='Gender Distribution'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar( \n",
    "    spark.sql(\"select gender, maritalStatus, count(*) count from local.silver.patient group by 1,2\").toPandas(), \n",
    "    x='maritalStatus', \n",
    "    y='count', \n",
    "    color='gender', \n",
    "    title='Count by Gender and Marital Status', \n",
    "    barmode='group' \n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encounter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"\n",
    "    select date_format(periodStart, 'yyyy') encounterYear, count(*) count from local.silver.encounter group by 1 order by 1\n",
    "    \"\"\").toPandas(),\n",
    "    x='encounterYear',\n",
    "    y='count',\n",
    "    title='Encounter Period Year Distribution [De-Identified]'\n",
    ").update_layout(\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Number of Encounters',\n",
    "    template='plotly_white'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select sourceFile, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='sourceFile', title='Source Distribution').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select encounterClass, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='encounterClass', title='Encounter Class Distribution').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select priority, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='priority', title='Encounter Class by Priority').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select readmissionStatus, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='readmissionStatus', title='Patient Readmission').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"select readmissionStatus, year(periodStart) year, count(*) count\n",
    "    from local.silver.encounter group by 1,2 order by 2\"\"\").toPandas(),\n",
    "    x='year',\n",
    "    y='count',\n",
    "    color='readmissionStatus', # Differentiate lines by readmissionStatus\n",
    "    title='Encounter Over the Years by ReadmissionStatus',\n",
    "    labels={'year': 'Year', 'count': 'Number of Encounters'}).update_layout(\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Number of Encounters',\n",
    "    legend_title='Readmission Status',\n",
    "    template='plotly_white'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_encounter_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    e1.priority priority1,\n",
    "    e2.priority priority2,\n",
    "    count(*) count\n",
    "FROM local.silver.encounter e1\n",
    "JOIN local.silver.encounter e2\n",
    "ON e1.nextEncounterId = e2.encounterID\n",
    "WHERE e1.readmissionStatus == 'Readmission'\n",
    "GROUP BY all\n",
    "ORDER by 3 desc\n",
    "\"\"\")\n",
    "\n",
    "priority_encounter_pd = priority_encounter_df.toPandas()\n",
    "all_priorities = list(set(priority_encounter_pd['priority1'].tolist() +\n",
    "                          priority_encounter_pd['priority2'].tolist()))\n",
    "node_map = {priority: idx for idx, priority in enumerate(all_priorities)}\n",
    "priority_encounter_pd['source'] = priority_encounter_pd['priority1'].map(node_map)\n",
    "priority_encounter_pd['target'] = priority_encounter_pd['priority2'].map(node_map)\n",
    "\n",
    "table_trace = go.Table(\n",
    "    header=dict(values=[\"Priority 1\", \"Priority 2\", \"Count\"], fill_color='lightgrey', align='center'),\n",
    "    cells=dict(values=[priority_encounter_pd['priority1'], priority_encounter_pd['priority2'], priority_encounter_pd['count']],\n",
    "               fill_color='white', align='center')\n",
    ")\n",
    "\n",
    "sankey_trace = go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15, # Padding between nodes\n",
    "        thickness=20, # Node thickness\n",
    "        line=dict(color=\"black\", width=0.5), # Node border settings\n",
    "        label=all_priorities # Node labels\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=priority_encounter_pd['source'], # Source nodes (indices)\n",
    "        target=priority_encounter_pd['target'], # Target nodes (indices)\n",
    "        value=priority_encounter_pd['count'] # Flow values (counts)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    column_widths=[0.7, 0.3], # Adjust column widths (30% table, 70% Sankey)\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"sankey\"}]], # Specify types for each subplot\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(sankey_trace, row=1, col=1)\n",
    "fig.add_trace(table_trace, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Readmission Encounters: Priority Transitions Sankey Diagram and Table\",\n",
    "    font_size=12,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    sourceFile,\n",
    "    CASE\n",
    "        WHEN duration BETWEEN 0 AND 5 THEN '0 to 5 days'\n",
    "        WHEN duration BETWEEN 6 AND 10 THEN '6 to 10 days'\n",
    "        WHEN duration BETWEEN 11 AND 20 THEN '11 to 20 days'\n",
    "        WHEN duration BETWEEN 21 AND 30 THEN '21 to 30 days'\n",
    "        WHEN duration BETWEEN 31 AND 50 THEN '31 to 50 days'\n",
    "        WHEN duration BETWEEN 51 AND 100 THEN '51 to 100 days'\n",
    "        WHEN duration BETWEEN 101 AND 150 THEN '101 to 150 days'\n",
    "        WHEN duration BETWEEN 151 AND 200 THEN '151 to 200 days'\n",
    "        WHEN duration BETWEEN 201 AND 250 THEN '201 to 250 days'\n",
    "        WHEN duration BETWEEN 251 AND 300 THEN '251 to 300 days'\n",
    "        ELSE 'More than 300 days'\n",
    "    END AS duration_group,\n",
    "    COUNT(*) AS encounter_count\n",
    "FROM local.silver.encounter\n",
    "GROUP BY sourceFile, duration_group\n",
    "ORDER BY sourceFile, double(split_part(duration_group, ' ', 1));\n",
    "\"\"\").show(50, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"SELECT\n",
    "        sourceFile,\n",
    "        duration AS duration_group,\n",
    "        COUNT(*) AS encounter_count\n",
    "    FROM local.silver.encounter\n",
    "    where duration BETWEEN 1 AND 30\n",
    "    GROUP BY sourceFile, duration_group\n",
    "    ORDER BY sourceFile, duration_group;\"\"\").toPandas(),\n",
    "    x='duration_group', y='encounter_count', color='sourceFile',\n",
    "    markers=True, title=\"Encounter Count by Source and Duration Group\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select split_part(conditionSystem, '/', -1) conditionSystem, count(*) count from local.silver.condition group by 1\").toPandas(),\n",
    "    values='count', names='conditionSystem', title='Condition System Count Distribution').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the `Condition System Count Distribution` chart, the dataset incorporates both ICD-9 and ICD-10 coding systems in condition table.\n",
    "\n",
    "<!-- The difference between these two coding systems can introduce challenges which may affect the model performance and interpretability.\n",
    "\n",
    "1. Inconsistent Coding:\n",
    "    - ICD-10 has more granularity in specifying types of diseases, injury location, and severity.\n",
    "    - ICD-9 has fewer and less specific codes than ICD-10, which means that a single ICD-9 code could map to multiple ICD-10 codes.\n",
    "    - This inconsistency can create noisy features in your dataset if the same condition is coded differently depending on the coding system used. This could confuse your model, leading to reduced predictive accuracy.\n",
    "2. Feature Engineering Complexity:\n",
    "    - ICD-9 and ICD-10 are structured differently, both in terms of the number of codes and their specificity.\n",
    "    - This complicates the creation of features related to diagnosis categories or comorbidities.\n",
    "    - The features might not capture the full clinical picture, potentially leading to underfitting or overfitting\n",
    "3. Data Heterogeneity:\n",
    "    - Introduction of temporal bias into the model\n",
    "    - This could cause the model to overestimate or underestimate readmission risks if it correlates newer coding systems with better or worse outcomes.\n",
    "4. Model Interpretability:\n",
    "    - Mixed coding systems make model interpretation harder, especially if using interpretable models like decision trees or logistic regression.\n",
    "    - This may end up with features that are not comparable between ICD-9 and ICD-10, complicating efforts to explain your model's predictions.\n",
    "\n",
    "> **References**\n",
    "> - [Understanding the Impact of the Differences in ICD-9-CM and ICD10-CM and Its Potential Impact on Data Analysis | National Center for Health Statistics](https://www.cdc.gov/nchs/ppt/nchs2012/li-01_pickett.pdf)\n",
    "> - [Overview of Coding and Classification Systems](https://www.cms.gov/cms-guide-medical-technology-companies-and-other-interested-parties/coding/overview-coding-classification-systems) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select conditionCode, conditionDisplay, count(*) count from local.silver.condition\n",
    "where conditionSystem like '%mimic-diagnosis-icd10'\n",
    "group by all order by 3 desc\n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select conditionCode, conditionDisplay, count(*) count from local.silver.condition\n",
    "where conditionSystem like '%mimic-diagnosis-icd9'\n",
    "group by all order by 3 desc\n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing top condition for both coding systems, there are few notable common types between them.\n",
    "\n",
    "For Example:\n",
    "\n",
    "- ICD 9 Code 4019 `Unspecified essential hypertension` is similar to ICD 10 Code I10 `Essential (primary) hypertension`.\n",
    "- ICD 9 Code V1582 `Personal history of tobacco use` is similar to ICD 10 Code Z87891 `Personal history of nicotine dependence`.\n",
    "- ICD 9 Code 2724 `Other and unspecified hyperlipidemia ` is similar to ICD 10 Code E785 `Hyperlipidemia, unspecified`.\n",
    "\n",
    "The dataset must be standardized in order to gain better accuracy of predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardarize Coding System\n",
    "\n",
    "<!-- The dataset, as shown in the Condition System Count Distribution chart, includes both ICD-9 and ICD-10 coding systems in the condition table.\n",
    "\n",
    "To standardize the dataset, one approach is to map ICD-9 codes to their ICD-10 equivalents using tools like General Equivalence Mappings (GEMs).\n",
    "\n",
    "This conversion ensures consistency across the dataset by aligning all condition codes with the ICD-10 system, which is the current standard for coding medical diagnoses and procedures.\n",
    "\n",
    "**ICD-10 Code Structure**\n",
    "- Characters 1:3 = Indicate the category of the diagnosis\n",
    "- Characters 4:6 = Indicate etiology, anatomic site, severity or other clinical detail\n",
    "- Character 7 = Extension\n",
    "\n",
    "> **References**\n",
    "> - [Crosswalk or General Equivalence Mappings | NBER](https://www.nber.org/research/data/icd-9-cm-and-icd-10-cm-and-icd-10-pcs-crosswalk-or-general-equivalence-mappings) -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_standard ( \n",
    "    conditionId STRING, \n",
    "    encounterId STRING, \n",
    "    patientId STRING, \n",
    "    conditionCode STRING \n",
    ") USING iceberg; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10_df = spark.sql(\"\"\" \n",
    "    SELECT \n",
    "        conditionId, encounterId, patientId, conditionCode \n",
    "    FROM local.silver.condition condition \n",
    "    WHERE condition.conditionSystem LIKE '%icd10' \n",
    "\"\"\") \n",
    "icd10_df.write.format(\"iceberg\").mode(\"append\").save(\"local.silver.condition_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dataset/icd9toicd10cmgem.csv\", header = True) \n",
    "df.createOrReplaceTempView(\"GemMapping\") \n",
    "\n",
    "icd9_df = spark.sql(\"\"\" \n",
    "    SELECT \n",
    "        condition.conditionId, \n",
    "        condition.encounterId, \n",
    "        condition.patientId, \n",
    "        GemMapping.icd10cm conditionCode \n",
    "    FROM local.silver.condition condition \n",
    "    JOIN GemMapping \n",
    "    ON condition.conditionCode = GemMapping.icd9cm \n",
    "    WHERE condition.conditionSystem LIKE '%icd9' \n",
    "\"\"\") \n",
    "icd9_df.write.format(\"iceberg\").mode(\"append\").save(\"local.silver.condition_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "select \n",
    "    conditionID, encounterID, patientID, \n",
    "    conditionCode \n",
    "from local.silver.condition_standard \n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Categorization\n",
    "\n",
    "<!-- **Risk categorization based on the Charlson Comorbidity Index (CCI)**\n",
    "\n",
    "Risk categorization based on the Charlson Comorbidity Index (CCI) is a widely used method for assessing the risk of adverse outcomes in patients, particularly in healthcare settings. The CCI assigns weights to various comorbid conditions based on their severity, such as heart disease, diabetes, and cancer. These conditions are then summed to produce a total score, which can be used to predict patient outcomes, including the risk of mortality and complications. The higher the CCI score, the greater the patient’s risk. This index helps clinicians and healthcare providers identify high-risk patients, prioritize care, and make informed decisions regarding treatment plans, resource allocation, and follow-up care. It is an essential tool for improving patient outcomes and optimizing healthcare management.\n",
    "\n",
    "| Condition                             | Weight | Risk Level |\n",
    "|---------------------------------------|--------|------------|\n",
    "| Peripheral vascular disease           | 1      | Low        |\n",
    "| Cerebrovascular disease               | 1      | Low        |\n",
    "| Chronic pulmonary disease             | 1      | Low        |\n",
    "| Congestive heart failure              | 1      | Low        |\n",
    "| Rheumatic disease                     | 1      | Low        |\n",
    "| Diabetes without chronic complication | 1      | Low        |\n",
    "| Mild liver disease                    | 1      | Low        |\n",
    "| Peptic ulcer disease                  | 1      | Low        |\n",
    "| Renal disease                         | 1      | Low        |\n",
    "| Myocardial infarction                 | 2      | Moderate   |\n",
    "| Hemiplegia or paraplegia              | 2      | Moderate   |\n",
    "| Malignancy                            | 2      | Moderate   |\n",
    "| Diabetes with chronic complication    | 2      | Moderate   |\n",
    "| Moderate or severe liver disease      | 3      | High       |\n",
    "| Metastatic solid tumour               | 6      | High       |\n",
    "| AIDS/HIV                              | 6      | High       |\n",
    "\n",
    "> **References**\n",
    "> - [Charlson Comorbidity Index Calculator](https://www.mdcalc.com/calc/3917/charlson-comorbidity-index-cci)\n",
    "> - [Calculation of the Charlson Comorbidity Index score](https://www.ncbi.nlm.nih.gov/books/NBK587905/)\n",
    "> - [ICD-10-CM to CMS-HCC Crosswalk](https://provider.amerigroup.com/dam/publicdocuments/ALL_CARE_CMSHCCRAModel_mrdcoding_tips.pdf)\n",
    "> - [CCI ICD-10 codes Mapping](https://www.psychiatryinvestigation.org/upload/media/pi-2021-0223-suppl1.pdf) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_risk ( \n",
    "    conditionId STRING, \n",
    "    encounterId STRING, \n",
    "    patientId STRING, \n",
    "    conditionCode STRING, \n",
    "    charlsonCategory STRING, \n",
    "    riskWeight INT, \n",
    "    riskLevel STRING \n",
    ") USING iceberg; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_risk_df = spark.sql(\"\"\" \n",
    "with charlsonCategoryCondition as ( \n",
    "select \n",
    "    conditionID, \n",
    "    encounterID, patientID, \n",
    "    conditionCode, \n",
    "    CASE \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"1252\") \n",
    "            OR substring(conditionCode, 0, 4) like 'I21%' \n",
    "            OR substring(conditionCode, 0, 4) like 'I22%' \n",
    "        THEN 'Myocardial infarction' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I099\",\"I110\",\"I130\",\"I132\",\"I255\",\"I420\",\"I425\",\"I426\",\"I427\",\"I428\",\"I429\",\"P290\") \n",
    "            OR substring(conditionCode, 0, 4) like 'I43%' \n",
    "            OR substring(conditionCode, 0, 4) like 'I50%' \n",
    "        THEN 'Congestive heart failure' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I731\",\"I738\",\"I739\",\"I771\",\"I790\",\"I792\",\"K551\",\"K558\",\"K559\",\"Z958\",\"Z959\") \n",
    "            OR substring(conditionCode, 0, 4) like 'I70%' \n",
    "            OR substring(conditionCode, 0, 4) like 'I71%' \n",
    "        THEN 'Peripheral vascular disease' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"F051\",\"G311\") \n",
    "            OR substring(conditionCode, 0, 4) like \"F00%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"F01%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"F02%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"F03%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"G30%\" \n",
    "        THEN 'Cerebrovascular disease' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I278\",\"I279\",\"J684\",\"J701\",\"J703\") \n",
    "            OR substring(conditionCode, 0, 4) like \"J40%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J41%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J42%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J43%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J44%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J45%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J46%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J47%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J60%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J61%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J62%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J63%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J64%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J65%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J66%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"J67%\" \n",
    "        THEN 'Chronic pulmonary disease' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"M315\", \"M351\",\"M353\",\"M360\") \n",
    "            OR substring(conditionCode, 0, 4) like \"M05%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"M06%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"M32%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"M32%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"M34%\" \n",
    "        THEN \"Rheumatic disease\" \n",
    "        WHEN substring(conditionCode, 0, 4) like \"K25%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"K26%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"K27%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"K28%\" \n",
    "        THEN \"Peptic ulcer disease\" \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"K700\",\"K701\",\"K702\",\"K703\",\"K709\",\"K713\",\"K714\",\"K715\",\"K717\",\"K760\",\"K762\",\"K763\",\"K764\",\"K768\",\"K769\",\"Z944\") \n",
    "            OR substring(conditionCode, 0, 4) like 'B18%' \n",
    "            OR substring(conditionCode, 0, 4) like 'K73%' \n",
    "            OR substring(conditionCode, 0, 4) like 'K74%' \n",
    "        THEN 'Mild liver disease' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"E100\",\"E101\",\"E106\",\"E108\",\"E109\",\"E110\",\"E111\",\"E116\",\"E118\",\"E119\",\"E120\",\"E121\",\"E126\",\"E128\",\"E129\",\"E130\",\"E131\",\"E136\",\"E138\",\"E139\",\"E140\",\"E141\",\"E146\",\"E148\",\"E149\") \n",
    "        THEN 'Diabetes without chronic complication' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"E102\",\"E103\",\"E104\",\"E105\",\"E107\",\"E112\",\"E113\",\"E114\",\"E115\",\"E117\",\"E122\",\"E123\",\"E124\",\"E125\",\"E127\",\"E132\",\"E133\",\"E134\",\"E135\",\"E137\",\"E142\",\"E143\",\"E144\",\"E145\",\"E147\") \n",
    "        THEN 'Diabetes with chronic complication' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"G041\",\"G114\",\"G801\",\"G802\",\"G830\",\"G831\",\"G832\",\"G833\",\"G834\",\"G839\") \n",
    "            OR substring(conditionCode, 0, 4) like 'G81%' \n",
    "            OR substring(conditionCode, 0, 4) like 'G82%' \n",
    "        THEN 'Hemiplegia or paraplegia' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I120\",\"I131\",\"N032\",\"N033\",\"N034\",\"N035\",\"N036\",\"N037\",\"N052\",\"N053\",\"N054\",\"N055\",\"N056\",\"N057\",\"N250\",\"Z490\",\"Z491\",\"Z492\",\"Z940\",\"Z992\") \n",
    "            OR substring(conditionCode, 0, 4) like 'N18%' \n",
    "            OR substring(conditionCode, 0, 4) like 'N19%' \n",
    "        THEN 'Renal disease' \n",
    "        WHEN substring(conditionCode, 0, 4) like \"C0%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C1%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C20%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C21%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C22%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C23%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C24%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C25%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C26%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C30%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C31%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C32%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C33%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C34%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C37%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C38%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C39%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C40%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C41%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C43%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C45%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C46%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C47%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C48%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C49%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C50%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C51%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C52%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C53%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C54%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C55%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C56%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C57%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C58%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C60%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C61%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C62%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C63%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C64%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C65%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C66%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C67%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C68%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C69%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C70%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C71%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C72%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C73%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C74%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C75%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C76%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C81%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C82%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C83%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C84%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C85%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C88%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C90%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C91%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C92%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C93%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C94%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C95%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C96%\" \n",
    "            OR substring(conditionCode, 0, 4) like \"C97%\" \n",
    "        THEN 'Malignancy' \n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I850\",\"I859\",\"I864\",\"I982\",\"K704\",\"K711\",\"K721\",\"K729\",\"K765\",\"K766\",\"K767\") \n",
    "        THEN 'Moderate or severe liver disease' \n",
    "        WHEN substring(conditionCode, 0, 4) like 'C77%' \n",
    "            OR substring(conditionCode, 0, 4) like 'C78%' \n",
    "            OR substring(conditionCode, 0, 4) like 'C79%' \n",
    "            OR substring(conditionCode, 0, 4) like 'C80%' \n",
    "        THEN \"Metastatic solid tumour\" \n",
    "        WHEN substring(conditionCode, 0, 4) like 'B20%' \n",
    "            OR substring(conditionCode, 0, 4) like 'B21%' \n",
    "            OR substring(conditionCode, 0, 4) like 'B22%' \n",
    "            OR substring(conditionCode, 0, 4) like 'B24%' \n",
    "        THEN \"AIDS/HIV\" \n",
    "    END AS charlsonCategory \n",
    "from local.silver.condition_standard \n",
    ") \n",
    "select \n",
    "    conditionID, \n",
    "    encounterID, patientID, \n",
    "    conditionCode, charlsonCategory, \n",
    "    CASE \n",
    "        WHEN charlsonCategory IN (\"Peripheral vascular disease\", \"Cerebrovascular disease\", \"Chronic pulmonary disease\", \"Congestive heart failure\", \"Rheumatic disease\", \"Diabetes without chronic complication\", \"Mild liver disease\", \"Peptic ulcer disease\", \"Renal disease\") \n",
    "        THEN 1 \n",
    "        WHEN charlsonCategory IN (\"Myocardial infarction\", \"Hemiplegia or paraplegia\", \"Malignancy\", \"Diabetes with chronic complication\") \n",
    "        THEN 2 \n",
    "        WHEN charlsonCategory IN (\"Moderate or severe liver disease\") \n",
    "        THEN 3 \n",
    "        WHEN charlsonCategory IN (\"Metastatic solid tumour\", \"AIDS/HIV\") \n",
    "        THEN 6 \n",
    "        ELSE 0 \n",
    "    END riskWeight, \n",
    "    CASE \n",
    "        WHEN charlsonCategory IN (\"Peripheral vascular disease\", \"Cerebrovascular disease\", \"Chronic pulmonary disease\", \"Congestive heart failure\", \"Rheumatic disease\", \"Diabetes without chronic complication\", \"Mild liver disease\", \"Peptic ulcer disease\", \"Renal disease\") \n",
    "        THEN \"Low\" \n",
    "        WHEN charlsonCategory IN (\"Myocardial infarction\", \"Hemiplegia or paraplegia\", \"Malignancy\", \"Diabetes with chronic complication\") \n",
    "        THEN \"Moderate\" \n",
    "        WHEN charlsonCategory IN (\"Moderate or severe liver disease\", \"Metastatic solid tumour\", \"AIDS/HIV\") \n",
    "        THEN \"High\" \n",
    "        ELSE charlsonCategory \n",
    "    END riskLevel \n",
    "from charlsonCategoryCondition; \n",
    "\"\"\") \n",
    "\n",
    "condition_risk_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition_risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select charlsonCategory, riskLevel, count(*) from local.silver.condition_risk group by 1,2\").show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-Based Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_rollup ( \n",
    "    encounterId STRING, \n",
    "    patientID STRING, \n",
    "    riskScore INT, \n",
    "    highRiskCondition INT, \n",
    "    moderateRiskCondition INT, \n",
    "    lowRiskCondition INT \n",
    ") USING iceberg; \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_rollup_df = spark.sql(\"\"\" \n",
    "SELECT \n",
    "    encounterId, \n",
    "    patientID, \n",
    "    SUM(riskWeight) riskScore, \n",
    "    SUM(CASE WHEN riskLevel = 'High' THEN 1 ELSE 0 END) AS highRiskCondition, \n",
    "    SUM(CASE WHEN riskLevel = 'Moderate' THEN 1 ELSE 0 END) AS moderateRiskCondition, \n",
    "    SUM(CASE WHEN riskLevel = 'Low' THEN 1 ELSE 0 END) AS lowRiskCondition \n",
    "FROM local.silver.condition_risk \n",
    "GROUP BY encounterId, patientID; \n",
    "\"\"\") \n",
    "condition_rollup_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition_rollup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_rollup_df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated Encounter\n",
    "\n",
    "The Gold Layer represents the refined stage in the Medallion Architecture, where data from the Silver Layer is consolidated and fully processed for advanced analytics and reporting. The Gold Table serves as the foundation for high-level analysis, enabling analysts, and researchers to derive meaningful insights that drive operational efficiency, improve patient outcomes, and support value-based care initiatives.\n",
    "\n",
    "The Encounter Gold Table integrates and structures the most critical data points related to patient encounters, ensuring that it is clean, accurate, and ready for decision-making. The table has various data points (such as patient demographics, encounter details, clinical diagnoses) merged and aggregated into a comprehensive, easily accessible format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" \n",
    "    SELECT \n",
    "        encounter.encounterId, \n",
    "        encounter.patientId, \n",
    "        patient.gender, \n",
    "        CASE \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 18 AND 29 THEN 'young adults' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 30 AND 39 THEN 'young adulthood' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 40 AND 49 THEN 'early-middle age' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 50 AND 59 THEN 'late-middle age' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 60 AND 69 THEN 'mid-old age' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 70 AND 79 THEN 'senior-old age' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 80 AND 89 THEN 'very senior-old' \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 90 AND 115 THEN 'centenarians' \n",
    "            ELSE 'other age groups' \n",
    "        END AS ageGroup, \n",
    "        patient.maritalStatus, \n",
    "        encounter.duration stayLength, \n",
    "        encounter.status encounterStatus, \n",
    "        encounter.encounterClass, \n",
    "        encounter.admitSource, \n",
    "        encounter.dischargeDisposition, \n",
    "        encounter.displayType encounterType, \n",
    "        encounter.priority, \n",
    "        IFNULL(condition.riskScore, 0) riskScore, \n",
    "        IFNULL(condition.highRiskCondition, 0) highRiskCondition, \n",
    "        IFNULL(condition.moderateRiskCondition, 0) moderateRiskCondition, \n",
    "        IFNULL(condition.lowRiskCondition, 0) lowRiskCondition, \n",
    "        encounter.readmissionStatus \n",
    "    FROM local.silver.encounter \n",
    "    LEFT JOIN local.silver.patient \n",
    "        ON encounter.patientId = patient.patientID \n",
    "    LEFT JOIN local.silver.condition_rollup condition \n",
    "        ON encounter.encounterId = condition.encounterId \n",
    "        AND encounter.patientID = condition.patientID \n",
    "\"\"\").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
