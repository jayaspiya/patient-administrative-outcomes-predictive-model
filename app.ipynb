{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Administrative Outcomes Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Setup Development Environment\n",
    "\n",
    "- Install Poetry to simplify dependency management.\n",
    "    - `pip install poetry`\n",
    "- Setup Poetery Project\n",
    "    - `poetry init`\n",
    "- Create a virtual envrionment\n",
    "    - `python -m venv .venv`\n",
    "- Add dependencies \n",
    "    - `poetry add pyspark ipykernel pandas matplotlib ploty`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FhirDataApplication\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"dataset/iceberg\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FHIR Resources**\n",
    "- Patient: For demographic information.\n",
    "- Encounter: To track patient visits and interactions.\n",
    "- Condition: For diagnoses and health conditions.\n",
    "- Procedure: For medical procedures performed.\n",
    "- Observation: For lab results and vital signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS local.bronze.resource (\n",
    "    sourceFile STRING,\n",
    "    value STRING\n",
    "  ) USING iceberg;\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT sourceFile, count(value)\n",
    "FROM local.bronze.resource GROUP BY sourceFile\n",
    "\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_FILES = [\"MimicPatient.ndjson.gz\", \"MimicCondition.ndjson.gz\", \"MimicConditionED.ndjson.gz\", \"MimicEncounter.ndjson.gz\", \"MimicEncounterED.ndjson.gz\", \"MimicEncounterICU.ndjson.gz\"]\n",
    "for resource_file in RESOURCE_FILES:\n",
    "    resource_df =  spark.read.text(f\"dataset/{resource_file}\")\n",
    "    resource_df = resource_df.withColumn(\"sourceFile\", F.lit(resource_file))\n",
    "    resource_df.write.format(\"iceberg\").mode(\"append\").save(\"local.bronze.resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.read.format(\"iceberg\").load(\"local.bronze.resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.patient (\n",
    "    patientId        STRING,\n",
    "    gender           STRING,\n",
    "    birthDate        DATE,\n",
    "    maritalStatus    STRING,\n",
    "    sourceFile      STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicPatient.ndjson.gz\"))\n",
    "with open(\"schema/Patient.json\") as f:\n",
    "    schema_read = json.loads(f.read())\n",
    "schema =  T.StructType.fromJson(schema_read)\n",
    "patient_df = patient_df.withColumn(\"parsed_json\", F.from_json(patient_df[\"value\"], schema))\n",
    "patient_df = patient_df.select(\"parsed_json.*\", \"sourceFile\")\n",
    "patient_df.createOrReplaceTempView(\"patient_df\")\n",
    "\n",
    "fm_patient = spark.sql(\"\"\"\n",
    "select \n",
    "    id AS patientId,\n",
    "    gender AS gender,\n",
    "    to_date(birthDate) birthDate,\n",
    "    CASE maritalStatus.coding[0].code\n",
    "        WHEN \"M\" THEN \"Married\"\n",
    "        WHEN \"D\" THEN \"Divorced\"\n",
    "        WHEN \"W\" THEN \"Widowed\"\n",
    "        WHEN \"S\" THEN \"Never Married\"\n",
    "        ELSE \"Unknown\"\n",
    "    END maritalStatus,\n",
    "    sourceFile\n",
    "from patient_df\n",
    "\"\"\")\n",
    "\n",
    "fm_patient.show(5, truncate=False)\n",
    "fm_patient.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encounter FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.encounter (\n",
    "    encounterId          STRING,\n",
    "    patientId            STRING,\n",
    "    ref_encounterId      STRING,\n",
    "    periodStart          TIMESTAMP,\n",
    "    periodEnd            TIMESTAMP,\n",
    "    duration             INT,\n",
    "    status               STRING,\n",
    "    encounterClass       STRING,\n",
    "    displayType          STRING,\n",
    "    admitSource          STRING,\n",
    "    dischargeDisposition STRING,\n",
    "    priority             STRING,\n",
    "    nextEncounterId      STRING,\n",
    "    readmissionStatus    STRING,\n",
    "    sourceFile           STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicEncounter.ndjson.gz\", \"MimicEncounterED.ndjson.gz\"))\n",
    "with open(\"schema/Encounter.json\") as f:\n",
    "    schema_read = json.loads(f.read())\n",
    "schema =  T.StructType.fromJson(schema_read)\n",
    "encounter_df = encounter_df.withColumn(\"parsed_json\", F.from_json(encounter_df[\"value\"], schema))\n",
    "encounter_df = encounter_df.select(\"parsed_json.*\", \"sourceFile\")\n",
    "encounter_df.createOrReplaceTempView(\"encounter_df\")\n",
    "\n",
    "fm_encounter = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    id AS encounterId,\n",
    "    replace(subject.reference, \"Patient/\", \"\") AS patientId,\n",
    "    replace(partOf.reference, \"Encounter/\", \"\") AS ref_encounterId,\n",
    "    CAST(period.start AS timestamp) periodStart,\n",
    "    CAST(period.end AS timestamp) periodEnd,\n",
    "    date_diff(day, periodStart, periodEnd) duration,\n",
    "    status AS status,\n",
    "    CASE class.code \n",
    "        WHEN \"AMB\" THEN \"Ambulatory\"\n",
    "        WHEN \"OBSENC\" THEN \"Observation Encounter\"\n",
    "        WHEN \"ACUTE\" THEN \"Inpatient Acute\"\n",
    "        WHEN \"EMER\" THEN \"Emergency\"\n",
    "        WHEN \"SS\" THEN \"Short Stay\"\n",
    "    END AS encounterClass, \n",
    "    type[0].coding[0].display AS displayType,\n",
    "    hospitalization.admitSource.coding[0].code admitSource,\n",
    "    hospitalization.dischargeDisposition.coding[0].code dischargeDisposition,\n",
    "    nvl(priority.coding[0].display, 'emergency') AS priority,\n",
    "    -- Next EncounterID & Readmission Status\n",
    "    LEAD(id) OVER (PARTITION BY subject.reference ORDER BY period.start) AS nextEncounterId,\n",
    "    CASE \n",
    "        WHEN DATEDIFF(day, period.end, LEAD(period.start) OVER (PARTITION BY subject.reference ORDER BY period.start)) <= 30 THEN 'Readmission'\n",
    "        ELSE 'No Readmission'\n",
    "    END AS readmissionStatus,\n",
    "    sourceFile\n",
    "FROM encounter_df\n",
    "\"\"\")\n",
    "\n",
    "fm_encounter.show(5, truncate=False)\n",
    "fm_encounter.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.encounter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition (\n",
    "    conditionId         STRING,\n",
    "    patientId           STRING,\n",
    "    encounterId         STRING,\n",
    "    categoryCode        STRING,\n",
    "    conditionCode       STRING,\n",
    "    conditionDisplay    STRING,\n",
    "    conditionSystem     STRING,\n",
    "    sourceFile          STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df = raw_df.filter(raw_df.sourceFile.isin(\"MimicCondition.ndjson.gz\", \"MimicConditionED.ndjson.gz\"))\n",
    "with open(\"schema/Condition.json\") as f:\n",
    "    schema_read = json.loads(f.read())\n",
    "schema =  T.StructType.fromJson(schema_read)\n",
    "condition_df = condition_df.withColumn(\"parsed_json\", F.from_json(condition_df[\"value\"], schema))\n",
    "condition_df = condition_df.select(\"parsed_json.*\", \"sourceFile\")\n",
    "condition_df.createOrReplaceTempView(\"condition_df\")\n",
    "\n",
    "fm_condition = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    id AS conditionId,\n",
    "    replace(subject.reference, \"Patient/\", \"\") AS patientId,\n",
    "    replace(encounter.reference, \"Encounter/\", \"\") AS encounterId,\n",
    "    category[0].coding[0].code categoryCode,\n",
    "    code.coding[0].code AS conditionCode,\n",
    "    code.coding[0].display AS conditionDisplay,\n",
    "    code.coding[0].system AS conditionSystem,\n",
    "    sourceFile\n",
    "FROM condition_df\n",
    "\"\"\")\n",
    "\n",
    "fm_condition.show(5, truncate=False)\n",
    "fm_condition.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Domain\n",
    "\n",
    "- `patientID`: Unique identifier for the patient\n",
    "- `gender`: Gender of the patient (male/female)\n",
    "- `birthDate`: Birth Date\n",
    "- `maritalStatus`: Marital Status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"select date_format(birthDate, 'yyyy') birthYear, count(*) count  from local.silver.patient group by 1 order by 1\").toPandas(), \n",
    "    x='birthYear', \n",
    "    y='count', \n",
    "    title='Patient BirthYear Distribution [De-Identified]'\n",
    ").update_layout(\n",
    "    xaxis_title='Birth Year',\n",
    "    yaxis_title='Number of Patients',\n",
    "    template='plotly_white'  \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select gender, count(*) count  from local.silver.patient group by 1 order by 1\").toPandas(),\n",
    "    values='count', names='gender', title='Gender Distribution'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    spark.sql(\"select gender, maritalStatus, count(*) count  from local.silver.patient group by 1,2\").toPandas(), \n",
    "    x='maritalStatus', \n",
    "    y='count', \n",
    "    color='gender', \n",
    "    title='Count by Gender and Marital Status', \n",
    "    barmode='group'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encounter Domain\n",
    "\n",
    "The Encounter is a resource that represents an interaction between a patient and healthcare provider(s) for the purpose of providing healthcare services or assessing the patient's health status.\n",
    "\n",
    "It records the full span of a hospital stay, including admission, stay and discharge. It includes details such as admission start and end time, context for the admission and patient movements within the hospital.\n",
    "\n",
    "\n",
    "**Table Attributes**\n",
    "\n",
    "- `encounterId`: Unique identifier for the encounter.\n",
    "- `patientId`: Unique identifier for the patient.\n",
    "- `ref_encounterId`:Reference to a related encounter; can reference both future and past encounters.\n",
    "- `periodStart`: Start timestamp of the encounter period.\n",
    "- `periodEnd`:End timestamp of the encounter period.\n",
    "- `duration`: Total duration of encounter\n",
    "- `status`: Current status of the encounter (e.g., planned, in-progress, finished).\n",
    "- `encounterClass`: Classification of the encounter (e.g., inpatient, outpatient); Helps categorize the nature of the healthcare service provided.\n",
    "- `codedType`: Code representing the specific type of encounter.\n",
    "- `displayType`: Display name for the type of encounter.\n",
    "- `systemType`: System from which the type code is derived.\n",
    "- `priority`: Urgency of the encounter such as routine, urgent, or emergency; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"\n",
    "    select date_format(periodStart, 'yyyy') encounterYear, count(*) count  from local.silver.encounter group by 1 order by 1 \n",
    "    \"\"\").toPandas(), \n",
    "    x='encounterYear', \n",
    "    y='count', \n",
    "    title='Encounter Period Year Distribution [De-Identified]'\n",
    ").update_layout(\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Number of Encounters',\n",
    "    template='plotly_white'  \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select sourceFile, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='sourceFile', title='Source Distribution').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select encounterClass, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='encounterClass', title='Encounter Class Distribution').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select priority, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='priority', title='Encounter Class by Priority').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select readmissionStatus, count(*) count from local.silver.encounter group by 1\").toPandas(),\n",
    "values='count', names='readmissionStatus', title='Patient Readmission').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"select readmissionStatus, year(periodStart) year, count(*) count\n",
    "    from local.silver.encounter group by 1,2 order by 2\"\"\").toPandas(), \n",
    "    x='year', \n",
    "    y='count', \n",
    "    color='readmissionStatus',  # Differentiate lines by readmissionStatus\n",
    "    title='Encounter Over the Years by ReadmissionStatus', \n",
    "    labels={'year': 'Year', 'count': 'Number of Encounters'}).update_layout(\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Number of Encounters',\n",
    "    legend_title='Readmission Status',\n",
    "    template='plotly_white'  \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_encounter_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    e1.priority priority1,\n",
    "    e2.priority priority2,\n",
    "    count(*) count\n",
    "FROM local.silver.encounter e1\n",
    "JOIN local.silver.encounter e2\n",
    "ON e1.nextEncounterId = e2.encounterID\n",
    "WHERE e1.readmissionStatus == 'Readmission'\n",
    "GROUP BY all\n",
    "ORDER by 3 desc\n",
    "\"\"\")\n",
    "\n",
    "priority_encounter_pd = priority_encounter_df.toPandas()\n",
    "all_priorities = list(set(priority_encounter_pd['priority1'].tolist() + \n",
    "                          priority_encounter_pd['priority2'].tolist()))\n",
    "node_map = {priority: idx for idx, priority in enumerate(all_priorities)}\n",
    "priority_encounter_pd['source'] = priority_encounter_pd['priority1'].map(node_map)\n",
    "priority_encounter_pd['target'] = priority_encounter_pd['priority2'].map(node_map)\n",
    "\n",
    "table_trace = go.Table(\n",
    "    header=dict(values=[\"Priority 1\", \"Priority 2\", \"Count\"], fill_color='lightgrey', align='center'),\n",
    "    cells=dict(values=[priority_encounter_pd['priority1'], priority_encounter_pd['priority2'], priority_encounter_pd['count']],\n",
    "               fill_color='white', align='center')\n",
    ")\n",
    "\n",
    "sankey_trace = go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,  # Padding between nodes\n",
    "        thickness=20,  # Node thickness\n",
    "        line=dict(color=\"black\", width=0.5),  # Node border settings\n",
    "        label=all_priorities  # Node labels\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=priority_encounter_pd['source'],  # Source nodes (indices)\n",
    "        target=priority_encounter_pd['target'],  # Target nodes (indices)\n",
    "        value=priority_encounter_pd['count']     # Flow values (counts)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, \n",
    "    column_widths=[0.7, 0.3],  # Adjust column widths (30% table, 70% Sankey)\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"sankey\"}]],  # Specify types for each subplot\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(sankey_trace, row=1, col=1)\n",
    "fig.add_trace(table_trace, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Readmission Encounters: Priority Transitions Sankey Diagram and Table\",\n",
    "    font_size=12,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    sourceFile, \n",
    "    CASE \n",
    "        WHEN duration BETWEEN 0 AND 5 THEN '0 to 5 days'\n",
    "        WHEN duration BETWEEN 6 AND 10 THEN '6 to 10 days'\n",
    "        WHEN duration BETWEEN 11 AND 20 THEN '11 to 20 days'\n",
    "        WHEN duration BETWEEN 21 AND 30 THEN '21 to 30 days'\n",
    "        WHEN duration BETWEEN 31 AND 50 THEN '31 to 50 days'\n",
    "        WHEN duration BETWEEN 51 AND 100 THEN '51 to 100 days'\n",
    "        WHEN duration BETWEEN 101 AND 150 THEN '101 to 150 days'\n",
    "        WHEN duration BETWEEN 151 AND 200 THEN '151 to 200 days'\n",
    "        WHEN duration BETWEEN 201 AND 250 THEN '201 to 250 days'\n",
    "        WHEN duration BETWEEN 251 AND 300 THEN '251 to 300 days'\n",
    "        ELSE 'More than 300 days'\n",
    "    END AS duration_group,\n",
    "    COUNT(*) AS encounter_count\n",
    "FROM local.silver.encounter\n",
    "GROUP BY sourceFile, duration_group\n",
    "ORDER BY sourceFile, double(split_part(duration_group, ' ', 1));\n",
    "\"\"\").show(50, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    spark.sql(\"\"\"SELECT \n",
    "        sourceFile,\n",
    "        duration AS duration_group,\n",
    "        COUNT(*) AS encounter_count\n",
    "    FROM local.silver.encounter\n",
    "    where duration BETWEEN 1 AND 30\n",
    "    GROUP BY sourceFile, duration_group\n",
    "    ORDER BY sourceFile, duration_group;\"\"\").toPandas(),\n",
    "    x='duration_group', y='encounter_count', color='sourceFile',\n",
    "    markers=True, title=\"Encounter Count by Source and Duration Group\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Domain\n",
    "\n",
    "The Condition resource in FHIR is used to record detailed information about a patient’s health state, including diagnoses, problems, or other clinical concerns. Here are the key points:\n",
    "\n",
    "- Scope and Usage: It captures conditions that have risen to a level of concern, such as diseases, health issues, or post-procedure states.\n",
    "- Clinical Context: Conditions can be recorded based on a clinician’s assessment or expressed by the patient or care team members.\n",
    "- Examples: Conditions like pregnancy, post-surgical states, or chronic illnesses can be documented. It can also include social determinants of health like unemployment or lack of transportation.\n",
    "\n",
    "Data Preprocessing Condition Code System is both ICD 9 & ICD 10, Standardize ICD-9 and ICD-10 codes to a common standard. GEMs (General Equivalence Mappings) are crosswalks between ICD-9 and ICD-10 codes. They help map codes from ICD-9-CM to ICD-10-CM and vice versa.\n",
    "\n",
    "https://www.cms.gov/Medicare/Coding/ICD10/Downloads/ICD-10_GEM_fact_sheet.pdf\n",
    "\n",
    "**Table Attributes**\n",
    "\n",
    "- `conditionId`: The unique identifier for the condition.\n",
    "- `patientId`: The unique identifier for the patient.\n",
    "- `encounterId`: The unique identifier for the encounter.\n",
    "- `categoryCode`: Condition category.\n",
    "- `conditionCode`: The code representing the specific condition.\n",
    "- `conditionDisplay`: The display name for the condition.\n",
    "- `conditionSystem`: The system from which the condition code is derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(\n",
    "    spark.sql(\"select split_part(conditionSystem, '/', -1) conditionSystem, count(*) count from local.silver.condition group by 1\").toPandas(),\n",
    "    values='count', names='conditionSystem', title='Condition System Count Distribution').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the `Condition System Count Distribution` chart, the dataset incorporates both ICD-9 and ICD-10 coding systems in condition table.\n",
    "\n",
    "The difference between these two coding systems can introduce challenges which may affect the model performance and interpretability.\n",
    "\n",
    "1. Inconsistent Coding:\n",
    "    - ICD-10 has more granularity in specifying types of diseases, injury location, and severity.\n",
    "    - ICD-9 has fewer and less specific codes than ICD-10, which means that a single ICD-9 code could map to multiple ICD-10 codes.\n",
    "    - This inconsistency can create noisy features in your dataset if the same condition is coded differently depending on the coding system used. This could confuse your model, leading to reduced predictive accuracy.\n",
    "2. Feature Engineering Complexity:\n",
    "    - ICD-9 and ICD-10 are structured differently, both in terms of the number of codes and their specificity.\n",
    "    - This complicates the creation of features related to diagnosis categories or comorbidities.\n",
    "    - The features might not capture the full clinical picture, potentially leading to underfitting or overfitting\n",
    "3. Data Heterogeneity:\n",
    "    - Introduction of temporal bias into the model\n",
    "    - This could cause the model to overestimate or underestimate readmission risks if it correlates newer coding systems with better or worse outcomes.\n",
    "4. Model Interpretability:\n",
    "    - Mixed coding systems make model interpretation harder, especially if using interpretable models like decision trees or logistic regression.\n",
    "    - This may end up with features that are not comparable between ICD-9 and ICD-10, complicating efforts to explain your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select conditionCode, conditionDisplay, count(*) count from local.silver.condition\n",
    "where conditionSystem like '%mimic-diagnosis-icd10'\n",
    "group by all order by 3 desc \n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select conditionCode, conditionDisplay, count(*) count from local.silver.condition\n",
    "where conditionSystem like '%mimic-diagnosis-icd9'\n",
    "group by all order by 3 desc \n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing top condition for both coding systems, there are few notable common types between them.\n",
    "\n",
    "For Example:\n",
    "\n",
    "- ICD 9 Code 4019 `Unspecified essential hypertension` is similar to ICD 10 Code I10 `Essential (primary) hypertension`.\n",
    "- ICD 9 Code V1582 `Personal history of tobacco use` is similar to ICD 10 Code Z87891 `Personal history of nicotine dependence`.\n",
    "- ICD 9 Code 2724 `Other and unspecified hyperlipidemia\t` is similar to ICD 10 Code E785 `Hyperlipidemia, unspecified`.\n",
    "\n",
    "The dataset must be standardized in order to gain better accuracy of predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardarize Coding System\n",
    "\n",
    "One solution is to map ICD-9 codes to ICD-10 equivalents using tools like the General Equivalence Mappings (GEMs). This allows you to convert ICD-9 codes to ICD-10 to standardize the dataset.\n",
    "\n",
    "- Dataset Link: [ICD-9-CM to and from ICD-10-CM and ICD-10-PCS Crosswalk or General Equivalence Mappings](https://www.nber.org/research/data/icd-9-cm-and-icd-10-cm-and-icd-10-pcs-crosswalk-or-general-equivalence-mappings)\n",
    "\n",
    "**ICD-10 Code Structure**\n",
    "- Characters 1:3 = Indicate the category of the diagnosis\n",
    "- Characters 4:6 = Indicate etiology, anatomic site, severity or other clinical detail\n",
    "- Character 7 = Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_standard (\n",
    "    conditionId         STRING,\n",
    "    encounterId         STRING,\n",
    "    patientId           STRING,\n",
    "    conditionCode       STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        conditionId, encounterId, patientId, conditionCode\n",
    "    FROM local.silver.condition condition \n",
    "    WHERE condition.conditionSystem LIKE '%icd10'\n",
    "\"\"\")\n",
    "icd10_df.write.format(\"iceberg\").mode(\"append\").save(\"local.silver.condition_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dataset/icd9toicd10cmgem.csv\", header = True)\n",
    "df.createOrReplaceTempView(\"GemMapping\")\n",
    "\n",
    "icd9_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        condition.conditionId,\n",
    "        condition.encounterId,\n",
    "        condition.patientId,\n",
    "        GemMapping.icd10cm conditionCode\n",
    "    FROM local.silver.condition condition\n",
    "    JOIN GemMapping\n",
    "    ON condition.conditionCode = GemMapping.icd9cm\n",
    "    WHERE condition.conditionSystem LIKE '%icd9'\n",
    "\"\"\")\n",
    "icd9_df.write.format(\"iceberg\").mode(\"append\").save(\"local.silver.condition_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select\n",
    "    conditionID, encounterID, patientID,\n",
    "    conditionCode\n",
    "from local.silver.condition_standard\n",
    "\"\"\").show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Categorization\n",
    "**Risk categorization based on the Charlson Comorbidity Index (CCI)**\n",
    "| Condition                             | Weight | Risk Level |\n",
    "|---------------------------------------|--------|------------|\n",
    "| Peripheral vascular disease           | 1      | Low        |\n",
    "| Cerebrovascular disease               | 1      | Low        |\n",
    "| Chronic pulmonary disease             | 1      | Low        |\n",
    "| Congestive heart failure              | 1      | Low        |\n",
    "| Rheumatic disease                     | 1      | Low        |\n",
    "| Diabetes without chronic complication | 1      | Low        |\n",
    "| Mild liver disease                    | 1      | Low        |\n",
    "| Peptic ulcer disease                  | 1      | Low        |\n",
    "| Renal disease                         | 1      | Low        |\n",
    "| Myocardial infarction                 | 2      | Moderate   |\n",
    "| Hemiplegia or paraplegia              | 2      | Moderate   |\n",
    "| Malignancy                            | 2      | Moderate   |\n",
    "| Diabetes with chronic complication    | 2      | Moderate   |\n",
    "| Moderate or severe liver disease      | 3      | High       |\n",
    "| Metastatic solid tumour               | 6      | High       |\n",
    "| AIDS/HIV                              | 6      | High       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_risk (\n",
    "    conditionId         STRING,\n",
    "    encounterId         STRING,\n",
    "    patientId           STRING,\n",
    "    conditionCode       STRING,\n",
    "    charlsonCategory    STRING,\n",
    "    riskWeight          INT,\n",
    "    riskLevel           STRING\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_risk_df = spark.sql(\"\"\"\n",
    "with charlsonCategoryCondition as (\n",
    "select\n",
    "    conditionID,\n",
    "    encounterID, patientID,\n",
    "    conditionCode,\n",
    "    CASE\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"1252\")\n",
    "            OR substring(conditionCode, 0, 4) like 'I21%'\n",
    "            OR substring(conditionCode, 0, 4) like 'I22%'\n",
    "        THEN 'Myocardial infarction'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I099\",\"I110\",\"I130\",\"I132\",\"I255\",\"I420\",\"I425\",\"I426\",\"I427\",\"I428\",\"I429\",\"P290\")\n",
    "            OR substring(conditionCode, 0, 4) like 'I43%'\n",
    "            OR substring(conditionCode, 0, 4) like 'I50%'\n",
    "        THEN 'Congestive heart failure'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I731\",\"I738\",\"I739\",\"I771\",\"I790\",\"I792\",\"K551\",\"K558\",\"K559\",\"Z958\",\"Z959\")\n",
    "            OR substring(conditionCode, 0, 4) like 'I70%'\n",
    "            OR substring(conditionCode, 0, 4) like 'I71%'\n",
    "        THEN 'Peripheral vascular disease'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"F051\",\"G311\")\n",
    "            OR substring(conditionCode, 0, 4) like \"F00%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"F01%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"F02%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"F03%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"G30%\"\n",
    "        THEN 'Cerebrovascular disease'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I278\",\"I279\",\"J684\",\"J701\",\"J703\")\n",
    "            OR substring(conditionCode, 0, 4) like \"J40%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J41%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J42%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J43%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J44%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J45%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J46%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J47%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J60%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J61%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J62%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J63%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J64%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J65%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J66%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"J67%\"\n",
    "        THEN 'Chronic pulmonary disease'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"M315\", \"M351\",\"M353\",\"M360\")\n",
    "            OR substring(conditionCode, 0, 4) like \"M05%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"M06%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"M32%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"M32%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"M34%\"\n",
    "        THEN \"Rheumatic disease\"\n",
    "        WHEN substring(conditionCode, 0, 4) like \"K25%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"K26%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"K27%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"K28%\"\n",
    "        THEN \"Peptic ulcer disease\"\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"K700\",\"K701\",\"K702\",\"K703\",\"K709\",\"K713\",\"K714\",\"K715\",\"K717\",\"K760\",\"K762\",\"K763\",\"K764\",\"K768\",\"K769\",\"Z944\")\n",
    "            OR substring(conditionCode, 0, 4) like 'B18%'\n",
    "            OR substring(conditionCode, 0, 4) like 'K73%'\n",
    "            OR substring(conditionCode, 0, 4) like 'K74%'\n",
    "        THEN 'Mild liver disease'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"E100\",\"E101\",\"E106\",\"E108\",\"E109\",\"E110\",\"E111\",\"E116\",\"E118\",\"E119\",\"E120\",\"E121\",\"E126\",\"E128\",\"E129\",\"E130\",\"E131\",\"E136\",\"E138\",\"E139\",\"E140\",\"E141\",\"E146\",\"E148\",\"E149\")\n",
    "        THEN 'Diabetes without chronic complication'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"E102\",\"E103\",\"E104\",\"E105\",\"E107\",\"E112\",\"E113\",\"E114\",\"E115\",\"E117\",\"E122\",\"E123\",\"E124\",\"E125\",\"E127\",\"E132\",\"E133\",\"E134\",\"E135\",\"E137\",\"E142\",\"E143\",\"E144\",\"E145\",\"E147\")\n",
    "        THEN 'Diabetes with chronic complication'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"G041\",\"G114\",\"G801\",\"G802\",\"G830\",\"G831\",\"G832\",\"G833\",\"G834\",\"G839\")\n",
    "            OR substring(conditionCode, 0, 4) like 'G81%'\n",
    "            OR substring(conditionCode, 0, 4) like 'G82%'\n",
    "        THEN 'Hemiplegia or paraplegia'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I120\",\"I131\",\"N032\",\"N033\",\"N034\",\"N035\",\"N036\",\"N037\",\"N052\",\"N053\",\"N054\",\"N055\",\"N056\",\"N057\",\"N250\",\"Z490\",\"Z491\",\"Z492\",\"Z940\",\"Z992\")\n",
    "            OR substring(conditionCode, 0, 4) like 'N18%'\n",
    "            OR substring(conditionCode, 0, 4) like 'N19%'\n",
    "        THEN 'Renal disease'\n",
    "        WHEN substring(conditionCode, 0, 4) like \"C0%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C1%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C20%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C21%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C22%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C23%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C24%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C25%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C26%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C30%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C31%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C32%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C33%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C34%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C37%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C38%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C39%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C40%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C41%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C43%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C45%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C46%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C47%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C48%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C49%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C50%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C51%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C52%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C53%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C54%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C55%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C56%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C57%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C58%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C60%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C61%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C62%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C63%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C64%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C65%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C66%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C67%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C68%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C69%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C70%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C71%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C72%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C73%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C74%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C75%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C76%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C81%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C82%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C83%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C84%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C85%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C88%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C90%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C91%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C92%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C93%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C94%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C95%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C96%\"\n",
    "            OR substring(conditionCode, 0, 4) like \"C97%\"\n",
    "        THEN 'Malignancy'\n",
    "        WHEN substring(conditionCode, 0, 4) IN (\"I850\",\"I859\",\"I864\",\"I982\",\"K704\",\"K711\",\"K721\",\"K729\",\"K765\",\"K766\",\"K767\")\n",
    "        THEN 'Moderate or severe liver disease'\n",
    "        WHEN substring(conditionCode, 0, 4) like 'C77%'\n",
    "            OR substring(conditionCode, 0, 4) like 'C78%'\n",
    "            OR substring(conditionCode, 0, 4) like 'C79%'\n",
    "            OR substring(conditionCode, 0, 4) like 'C80%'\n",
    "        THEN \"Metastatic solid tumour\"\n",
    "        WHEN substring(conditionCode, 0, 4) like 'B20%'\n",
    "            OR substring(conditionCode, 0, 4) like 'B21%'\n",
    "            OR substring(conditionCode, 0, 4) like 'B22%'\n",
    "            OR substring(conditionCode, 0, 4) like 'B24%'\n",
    "        THEN \"AIDS/HIV\"\n",
    "    END AS charlsonCategory\n",
    "from local.silver.condition_standard\n",
    ")\n",
    "select\n",
    "    conditionID,\n",
    "    encounterID, patientID,\n",
    "    conditionCode, charlsonCategory,\n",
    "    CASE\n",
    "        WHEN charlsonCategory IN (\"Peripheral vascular disease\", \"Cerebrovascular disease\", \"Chronic pulmonary disease\", \"Congestive heart failure\", \"Rheumatic disease\", \"Diabetes without chronic complication\", \"Mild liver disease\", \"Peptic ulcer disease\", \"Renal disease\")\n",
    "        THEN 1\n",
    "        WHEN charlsonCategory IN (\"Myocardial infarction\", \"Hemiplegia or paraplegia\", \"Malignancy\", \"Diabetes with chronic complication\")\n",
    "        THEN 2\n",
    "        WHEN charlsonCategory IN (\"Moderate or severe liver disease\")\n",
    "        THEN 3\n",
    "        WHEN charlsonCategory IN (\"Metastatic solid tumour\", \"AIDS/HIV\")\n",
    "        THEN 6\n",
    "        ELSE 0\n",
    "    END riskWeight,\n",
    "    CASE\n",
    "        WHEN charlsonCategory IN (\"Peripheral vascular disease\", \"Cerebrovascular disease\", \"Chronic pulmonary disease\", \"Congestive heart failure\", \"Rheumatic disease\", \"Diabetes without chronic complication\", \"Mild liver disease\", \"Peptic ulcer disease\", \"Renal disease\")\n",
    "        THEN \"Low\"\n",
    "        WHEN charlsonCategory IN (\"Myocardial infarction\", \"Hemiplegia or paraplegia\", \"Malignancy\", \"Diabetes with chronic complication\")\n",
    "        THEN \"Moderate\"\n",
    "        WHEN charlsonCategory IN (\"Moderate or severe liver disease\", \"Metastatic solid tumour\", \"AIDS/HIV\")\n",
    "        THEN \"High\"\n",
    "        ELSE charlsonCategory\n",
    "    END riskLevel\n",
    "from charlsonCategoryCondition;\n",
    "\"\"\")\n",
    "\n",
    "condition_risk_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition_risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select charlsonCategory, riskLevel, count(*) from local.silver.condition_risk group by 1,2\").show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-Based Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.silver.condition_rollup  (\n",
    "    encounterId           STRING,\n",
    "    patientID             STRING,\n",
    "    riskScore             INT,\n",
    "    highRiskCondition     INT,\n",
    "    moderateRiskCondition INT,\n",
    "    lowRiskCondition      INT\n",
    ") USING iceberg;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_rollup_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    encounterId,\n",
    "    patientID,\n",
    "    SUM(riskWeight) riskScore,\n",
    "    SUM(CASE WHEN riskLevel = 'High' THEN 1 ELSE 0 END) AS highRiskCondition,\n",
    "    SUM(CASE WHEN riskLevel = 'Moderate' THEN 1 ELSE 0 END) AS moderateRiskCondition,\n",
    "    SUM(CASE WHEN riskLevel = 'Low' THEN 1 ELSE 0 END) AS lowRiskCondition\n",
    "FROM local.silver.condition_risk\n",
    "GROUP BY encounterId, patientID;\n",
    "\"\"\")\n",
    "condition_rollup_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"local.silver.condition_rollup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_rollup_df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encounter Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        encounter.encounterId,\n",
    "        encounter.patientId,\n",
    "        patient.gender,\n",
    "        CASE \n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 18 AND 29 THEN 'young adults'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 30 AND 39 THEN 'young adulthood'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 40 AND 49 THEN 'early-middle age'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 50 AND 59 THEN 'late-middle age'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 60 AND 69 THEN 'mid-old age'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 70 AND 79 THEN 'senior-old age'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 80 AND 89 THEN 'very senior-old'\n",
    "            WHEN date_diff(year, patient.birthDate, encounter.periodStart) BETWEEN 90 AND 115 THEN 'centenarians'\n",
    "            ELSE 'other age groups'\n",
    "        END AS ageGroup,\n",
    "        patient.maritalStatus,\n",
    "        encounter.duration stayLength,\n",
    "        encounter.status encounterStatus,\n",
    "        encounter.encounterClass,\n",
    "        encounter.admitSource,\n",
    "        encounter.dischargeDisposition,\n",
    "        encounter.displayType encounterType,\n",
    "        encounter.priority,\n",
    "        IFNULL(condition.riskScore, 0) riskScore,\n",
    "        IFNULL(condition.highRiskCondition, 0) highRiskCondition,\n",
    "        IFNULL(condition.moderateRiskCondition, 0) moderateRiskCondition,\n",
    "        IFNULL(condition.lowRiskCondition, 0) lowRiskCondition,\n",
    "        encounter.readmissionStatus\n",
    "    FROM local.silver.encounter\n",
    "    LEFT JOIN local.silver.patient\n",
    "        ON encounter.patientId = patient.patientID\n",
    "    LEFT JOIN local.silver.condition_rollup condition\n",
    "        ON encounter.encounterId = condition.encounterId\n",
    "        AND encounter.patientID = condition.patientID\n",
    "\"\"\").show(30, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
