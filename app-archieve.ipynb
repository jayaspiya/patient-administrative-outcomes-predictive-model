{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Administrative Outcomes Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Setup Envrionment\n",
    "\n",
    "- Encrypt the disk with LUKS\n",
    "- [Encrypt on Folder Level with ENCFS](https://help.ubuntu.com/community/FolderEncryption)\n",
    "- Install Spark\n",
    "- Setup Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initalize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PostgreSQL connection properties\n",
    "connection_url = \"jdbc:postgresql://localhost:5432/my_fhir_project\"\n",
    "connection_config = {\n",
    "    \"user\": \"my_fhir_user\",\n",
    "    \"password\": \"**********\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FhirDataApplication\") \\\n",
    "    .config(\"spark.jars\", \"/home/snowblade/Downloads/postgresql-42.7.4.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 FHIR Integration | Medallion Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "CREATE TABLE IF NOT EXISTS bronze.patient_data (\n",
    "    value jsonb\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.encounter_data (\n",
    "    value jsonb\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.condition_data (\n",
    "    value jsonb\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.procedure_data (\n",
    "    value jsonb\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_patient_df =  spark.read.text(\"/home/snowblade/visible/MimicPatient.ndjson.gz\")\n",
    "\n",
    "bronze_patient_df.write.jdbc(\n",
    "    table=\"bronze.patient_data\",\n",
    "    mode=\"overwrite\",\n",
    "    url=connection_url,\n",
    "    properties=connection_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_encounter1_df =  spark.read.text(\"/home/snowblade/visible/MimicEncounter.ndjson.gz\")\n",
    "bronze_encounter2_df =  spark.read.text(\"/home/snowblade/visible/MimicEncounterED.ndjson.gz\")\n",
    "bronze_encounter_df =  bronze_encounter1_df.union(bronze_encounter2_df)\n",
    "\n",
    "bronze_encounter_df.write.jdbc(\n",
    "    table=\"bronze.encounter_data\",\n",
    "    mode=\"overwrite\",\n",
    "    url=connection_url,\n",
    "    properties=connection_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_condition1_df =  spark.read.text(\"/home/snowblade/visible/MimicCondition.ndjson.gz\")\n",
    "bronze_condition2_df =  spark.read.text(\"/home/snowblade/visible/MimicConditionED.ndjson.gz\")\n",
    "bronze_condition_df =  bronze_condition1_df.union(bronze_condition2_df)\n",
    "\n",
    "bronze_condition_df.write.jdbc(\n",
    "    table=\"bronze.condition_data\",\n",
    "    mode=\"overwrite\",\n",
    "    url=connection_url,\n",
    "    properties=connection_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_procedure1_df =  spark.read.text(\"/home/snowblade/visible/MimicProcedure.ndjson.gz\")\n",
    "bronze_procedure2_df =  spark.read.text(\"/home/snowblade/visible/MimicProcedureED.ndjson.gz\")\n",
    "bronze_procedure_df =  bronze_procedure1_df.union(bronze_procedure2_df)\n",
    "\n",
    "bronze_procedure_df.write.jdbc(\n",
    "    table=\"bronze.procedure_data\",\n",
    "    mode=\"overwrite\",\n",
    "    url=connection_url,\n",
    "    properties=connection_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Check Total Data Load\n",
    "SELECT 'bronze.patient_data', count(*) count from bronze.patient_data UNION \n",
    "SELECT 'bronze.encounter_data', count(*) count from bronze.encounter_data UNION \n",
    "SELECT 'bronze.condition_data', count(*) count from bronze.condition_data UNION \n",
    "SELECT 'bronze.procedure_data', count(*) count from bronze.procedure_data\n",
    "ORDER BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
